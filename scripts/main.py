import time

from rag.VDB_Common import *
from rag.Prompts import FinancialExpertPrompt
from data_processing.parser import PDFParser
from data_processing.chunker import TextSplitter
from model.embedModel import NVEmbed
from logger.exceptions import MissingDBInfoError, CollectionNotFoundError, SimpleRagWarning

from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from rag.llm import Llm
import warnings

class SimpleRAG(
    MilvusDB,
    PDFParser,
    NVEmbed,
    FinancialExpertPrompt,
    SimpleRagWarning
):

    def __init__(self, model: str) -> None:
        """
        Initialize the SimpleRAG instance.

        Args:
            model (str): The name of the language model to be used.
        """
        super().__init__()
        self.logger = Log(f'{os.path.basename(__file__)}').getlog()
        self.model = model
        self.llm = Llm(model=self.model)
        self.QA_CHAIN_PROMPT = self.get_prompt_template()

    def insert_VDB(self, colname: str, document_path: str):
        """
        Insert documents from a specified directory into the vector database.

        Args:
            colname (str): The name of the collection in the vector database.
            document_path (str): The path to the directory containing PDF documents.
        """
        if not self.is_collection_exists(colname):
            raise CollectionNotFoundError(colname)

        documents = self.load_directory(document_path, limit=3)
        text_splitter = TextSplitter(chunk_size=500, chunk_overlap=250)

        for document in documents:
            pdf_name = document['pdf_name'].replace('.pdf', '')
            pdf_text = document['pdf_text']
            if self.check_existing_file(colname=colname, pdf_name=pdf_name):
                continue

            self.logger.info(f'Inserting file: {pdf_name}')
            chunks = text_splitter.split_text(pdf_text)
            for i, chunk in enumerate(chunks):
                chunk_vector = self.embed_documents([chunk])
                data = [
                    [pdf_name], # pdf_name
                    [i], # chunk_number
                    [chunk], # chunk_text
                    chunk_vector # chunk_vector
                ]
                self.insert_collection(colname, data)
            self.logger.info(f'Inserted file - {pdf_name}')

    @staticmethod
    def format_docs(docs):
        """
        Format a list of document objects into a single string.

        Args:
            docs (List): A list of document objects containing page content.

        Returns:
            str: A concatenated string of all document page contents separated by two newlines.
        """
        return "\n\n".join(doc.page_content for doc in docs)

    def query_VDB(self, colname: str, user_query: str, pdf_name: str):
        """
        Query the vector database with a user query and retrieve relevant information.

        Args:
            colname (str): The name of the collection in the vector database.
            user_query (str): The user's query string.
            pdf_name (str): The name of the PDF document to query.

        Returns:
            str: The response generated by the language model based on the retrieved context.
        """
        if not self.is_collection_exists(colname):
            raise CollectionNotFoundError(colname)

        milvusWlangchain = MilvusWLangChain(colname=colname, pdf_name=pdf_name)

        self.logger.info('Retrieving relavant chunks from vector database...')
        retriever = milvusWlangchain.get_retriever(relavant_chunk_size=6)
        results = retriever.invoke(
            user_query
        )
        if results == []:
            warnings.warn(
                self.WarningQueryResult
            )
            self.logger.info(f'It does not access information from the vector database; '
                             f'therefore, the response relies solely on the LLM.')
        formatted_context = self.format_docs(results)
        self.logger.info('Relevant chunks have been retrieved')

        start_time = time.time()
        self.logger.info('Generating response from llm...')
        if self.WarningModel in self.model:
            warnings.warn(
                self._warningModelMsg(self.model)
            )

        rag_chain = (
                {"context": RunnablePassthrough(), "input": RunnablePassthrough()}
                | self.QA_CHAIN_PROMPT
                | self.llm
                | StrOutputParser()
        )
        rag_chain_input = {"context": formatted_context, "input": user_query}
        reply = rag_chain.invoke(rag_chain_input)
        end_time = time.time()
        seconds = end_time - start_time
        self.logger.info(f'It takes: {seconds}s to generate response from {self.model}')
        return reply

    def run(self,
            colname: str,
            document_path: str,
            user_query: str,
            pdf_name: str):
        """
        Execute the complete workflow: create collection if needed, insert documents, and process a user query.

        Args:
            colname (str): The name of the collection in the vector database.
            document_path (str): The path to the directory containing PDF documents.
            user_query (str): The user's query string.
            pdf_name (str): The name of the PDF document to query.
        """

        ############################### -- Create VDB -- ###############################
        self.logger.info("1. Start creating our vector database...")
        if not self.is_collection_exists(colname):
            self.logger.info(f'{colname} is not exist in our database, creating...')
            self.create_collection(colname)
        else:
            self.logger.info(f'{colname} existed in our database, proceed to next operation')

        ############################### -- Insert to VDB -- ###############################
        self.logger.info('2. Start parsing and inserting documents...')
        self.insert_VDB(colname, document_path)

        ############################### -- Search VDB and Reply from LLM -- ###############################
        self.logger.info('3. Start querying our VDB, and getting reply from LLM')
        reply = self.query_VDB(colname, user_query, pdf_name)
        self.logger.info(
            f'Reply from {self.model} successfully generated: \n'
            f'{reply}'
        )



if __name__ == '__main__':

    """
    Available models
    'gemma:7b',
    'gemma2:27b',
    'mistral:latest',
    'phi3:latest',
    'llama3.1:8b',
    'llama3.1:70b',
    'llama3.1:70b-instruct-q4_0'
    """
    simplerag = SimpleRAG('phi3:latest')
    simplerag.run(
        colname='col_test',
        document_path= '../_static',
        user_query='what is actuarial spread?',
        pdf_name='Actuarial Spread White Paper'
    )